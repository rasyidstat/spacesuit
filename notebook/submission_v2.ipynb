{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd09f92744e12c76bcce0c7412a206e46c8bf1a54cc67d5f25e706318e33507cbb7",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import structures\n",
    "\n",
    "# Model\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "# Others\n",
    "import torch\n",
    "import numpy as np\n",
    "import pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from imantics import Polygons, Mask\n",
    "from skimage import measure"
   ]
  },
  {
   "source": [
    "## Model Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 15\n",
    "cfg.OUTPUT_DIR = './output/keypoint_v0'\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold\n",
    "predictor_kp = DefaultPredictor(cfg)"
   ]
  },
  {
   "source": [
    "## Generate Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "893965.png\n",
      "1\n",
      "040364.png\n",
      "1\n",
      "223135.jpg\n",
      "1\n",
      "581725.png\n",
      "1\n",
      "617674.png\n",
      "1\n",
      "482414.jpg\n",
      "2\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-ae3233ab25d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutputs_kp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_kp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mselected_kp_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_kp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for file_path in os.listdir(\"data/raw/test/images/\"):\n",
    "    img = cv2.imread(\"data/raw/test/images/\" + file_path)\n",
    "    outputs = predictor(img)\n",
    "    outputs_kp = predictor_kp(img)\n",
    "    print(file_path)\n",
    "    if len(outputs[\"instances\"]) == 0:\n",
    "        res.append(file_path)\n",
    "    else:\n",
    "        print(len(outputs[\"instances\"]))\n",
    "        selected_kp_idx = structures.pairwise_iou(outputs[\"instances\"].pred_boxes, outputs_kp[\"instances\"].pred_boxes).argmax(1)\n",
    "        for i in range(len(outputs[\"instances\"])):\n",
    "            output_pred = outputs[\"instances\"].pred_masks[i]\n",
    "            output_pred = np.array(output_pred, dtype=np.uint8) \n",
    "            contours = measure.find_contours(output_pred, 0.5)\n",
    "\n",
    "            output_seg = []\n",
    "            for contour in contours:\n",
    "                contour = np.flip(contour, axis=1)\n",
    "                segmentation = contour.ravel().tolist()\n",
    "                output_seg.append(segmentation)\n",
    "\n",
    "            output_kp_pred = outputs_kp[\"instances\"].pred_keypoints[selected_kp_idx[i]]\n",
    "            \n",
    "            seg_all = ''\n",
    "            for a in output_seg:\n",
    "                seg = ''\n",
    "                for i, b in enumerate(a):\n",
    "                    if i+1 == len(a):\n",
    "                        seg = seg + str(b)\n",
    "                    else:\n",
    "                        seg = seg + str(b) + \",\"\n",
    "                seg = \"(\" + seg + \")\"\n",
    "                seg_all = seg_all + seg\n",
    "            seg_all = \"[\" + seg_all + \"]\"\n",
    "            \n",
    "            base = ','.join(map(str, torch.round(output_kp_pred.view(-1)).tolist()))\n",
    "            res.append(file_path + ',' + base + seg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sub/baseline_2d/solution/images/annotations/solution.txt', 'w') as f:\n",
    "    for item in res:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "source": [
    "## Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"data/raw/train/images/118330.png\")\n",
    "outputs = predictor(im)\n",
    "outputs_kp = predictor_kp(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'instances': Instances(num_instances=1, image_height=1080, image_width=1920, fields=[pred_boxes: Boxes(tensor([[ 532.4975,  770.8593, 1002.0208,  993.7135]])), scores: tensor([0.9595]), pred_classes: tensor([0]), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]])])}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Boxes(tensor([[ 533.6050,  769.1152,  964.2634,  997.7163],\n",
       "        [ 885.0015,  512.8485, 1169.5735, 1070.1250],\n",
       "        [1165.2817,  551.8598, 1397.6426, 1016.7322],\n",
       "        [1069.8679,  418.4604, 1175.0128,  681.3787],\n",
       "        [   0.0000,  979.8174,  114.6908, 1078.4587],\n",
       "        [1018.3921,  293.1704, 1099.1469,  484.2839],\n",
       "        [1149.9778,  296.8847, 1205.8925,  485.1429]]))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "outputs_kp[\"instances\"].pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0758, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0758, 1.0000, 0.0075, 0.0992, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0075, 1.0000, 0.0094, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0992, 0.0094, 1.0000, 0.0000, 0.0468, 0.0457],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0468, 0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0457, 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "structures.pairwise_iou(outputs_kp[\"instances\"].pred_boxes, outputs_kp[\"instances\"].pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "structures.pairwise_iou(outputs[\"instances\"].pred_boxes, outputs_kp[\"instances\"].pred_boxes).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "structures.pairwise_iou(outputs_kp[\"instances\"].pred_boxes[1:4], outputs_kp[\"instances\"].pred_boxes).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[5.7177e+02, 8.1440e+02, 1.8812e-02],\n",
       "        [5.5737e+02, 8.3885e+02, 5.8443e-02],\n",
       "        [5.8762e+02, 8.7910e+02, 2.2848e-02],\n",
       "        [6.6395e+02, 8.0578e+02, 4.1520e-02],\n",
       "        [7.2589e+02, 7.8134e+02, 1.9490e-02],\n",
       "        [7.2733e+02, 7.8134e+02, 6.6478e-03],\n",
       "        [6.0634e+02, 8.9636e+02, 5.3634e-02],\n",
       "        [6.0202e+02, 9.6824e+02, 2.6893e-01],\n",
       "        [5.5449e+02, 9.6105e+02, 9.1407e-02],\n",
       "        [7.5758e+02, 8.8629e+02, 4.5159e-02],\n",
       "        [8.7856e+02, 8.8054e+02, 6.2156e-02],\n",
       "        [9.4050e+02, 9.4668e+02, 1.3741e-02],\n",
       "        [7.7054e+02, 8.8773e+02, 3.1004e-01],\n",
       "        [8.4832e+02, 9.3661e+02, 7.8363e-02],\n",
       "        [5.5737e+02, 8.5466e+02, 2.9826e-02]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "outputs_kp[\"instances\"].pred_keypoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}